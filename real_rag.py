# real_rag.py - ì‹¤ì œ íŒŒì¼ì„ ì½ëŠ” RAG ì‹œìŠ¤í…œ
import os
from sentence_transformers import SentenceTransformer
import chromadb
from docx import Document

class RealRAG:
    def __init__(self):
        print("ğŸ”§ ì‹¤ì œ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
        self.client = chromadb.PersistentClient(path="./real_chroma_db")
        self.collection = self.client.get_or_create_collection("company_info")
        print("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì™„ë£Œ")
    
    def load_text_file(self, file_path):
        """í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ë‹¨ë³„ë¡œ ë¶„ë¦¬"""
        print(f"ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°: {file_path}")
        
        if not os.path.exists(file_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return []
        
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
        
        lines = content.split('\n')
        texts = []
        
        for i, line in enumerate(lines):
            line = line.strip()
            if line and len(line) > 5:
                texts.append({
                    'id': f'line_{i}',
                    'text': line
                })
        
        print(f"âœ… {len(texts)}ê°œì˜ ì •ë³´ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤")
        return texts
    
    def load_word_file(self, file_path):
        """Word íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ë‹¨ë³„ë¡œ ë¶„ë¦¬"""
        print(f"ğŸ“„ Word íŒŒì¼ ì½ê¸°: {file_path}")
        
        if not os.path.exists(file_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return []
        
        doc = Document(file_path)
        texts = []
        
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if text and len(text) > 5:
                texts.append({
                    'id': f'para_{i}',
                    'text': text
                })
        
        print(f"âœ… {len(texts)}ê°œì˜ ë¬¸ë‹¨ì„ ì½ì—ˆìŠµë‹ˆë‹¤")
        return texts
    
    def add_documents(self, texts):
        """ë¬¸ì„œë“¤ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€"""
        print("ğŸ”„ ì •ë³´ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€ ì¤‘...")
        
        try:
            self.client.delete_collection("company_info")
            self.collection = self.client.create_collection("company_info")
        except:
            pass
        
        documents = [item['text'] for item in texts]
        ids = [item['id'] for item in texts]
        
        self.collection.add(
            documents=documents,
            ids=ids
        )
        
        print(f"âœ… {len(documents)}ê°œ ì •ë³´ ì¶”ê°€ ì™„ë£Œ")
    
    def search(self, query, top_k=3):
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ê²€ìƒ‰"""
        print(f"ğŸ” ê²€ìƒ‰ ì¤‘: '{query}'")
        
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k
        )
        
        if results['documents'][0]:
            found_docs = results['documents'][0]
            print(f"âœ… {len(found_docs)}ê°œì˜ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤")
            return found_docs
        else:
            print("âŒ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
            return []
    
    def chat(self):
        """ëŒ€í™”í˜• ê²€ìƒ‰ ì‹œìŠ¤í…œ"""
        print("\nğŸ¤– íšŒì‚¬ ì •ë³´ ì±—ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ 'ì¢…ë£Œ' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
        print("-" * 50)
        
        while True:
            query = input("\nâ“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if query.lower() in ['ì¢…ë£Œ', 'quit', 'exit', 'ë‚˜ê°€ê¸°']:
                print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤!")
                break
            
            if not query:
                continue
            
            results = self.search(query)
            
            print("\nğŸ“‹ ê²€ìƒ‰ ê²°ê³¼:")
            if results:
                for i, result in enumerate(results, 1):
                    print(f"{i}. {result}")
            else:
                print("ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.")

def main():
    print("ğŸš€ ì‹¤ì œ RAG ì‹œìŠ¤í…œ ì‹œì‘!\n")
    
    rag = RealRAG()
    
    # ì—¬ê¸°ì— ì‹¤ì œ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš”
    file_path = "pstorm_pw.docx"  # ğŸ‘ˆ ì‹¤ì œ Word íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½
    
    # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ë‹¤ë¥¸ ì½ê¸° ë°©ì‹ ì‚¬ìš©
    if file_path.endswith('.docx'):
        texts = rag.load_word_file(file_path)
    else:
        texts = rag.load_text_file(file_path)
    
    if not texts:
        print("âŒ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    rag.add_documents(texts)
    
    print("\nğŸ¯ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸:")
    test_queries = ["ì™€ì´íŒŒì´ ë¹„ë²ˆ", "êµ¬ê¸€ ê³„ì •", "í”„ë¦°í„°"]
    
    for query in test_queries:
        print(f"\nğŸ” '{query}' ê²€ìƒ‰:")
        results = rag.search(query, top_k=1)
        if results:
            print(f"ğŸ’¡ ë‹µë³€: {results[0]}")
    
    rag.chat()

if __name__ == "__main__":
    main()