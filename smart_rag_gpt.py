# smart_rag_gpt.py - GPT í†µí•© RAG ì‹œìŠ¤í…œ (ì‹ ë²„ì „)
import os
from sentence_transformers import SentenceTransformer
import chromadb
from docx import Document
from openai import OpenAI
from dotenv import load_dotenv

class SmartRAGWithGPT:
    def __init__(self):
        print("ğŸ§  GPT í†µí•© RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
        load_dotenv()
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            print("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            self.client = None
            return
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì‹ ë²„ì „)
        self.client = OpenAI(api_key=api_key)
        print("âœ… OpenAI API í‚¤ ë¡œë“œ ì™„ë£Œ")
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
        self.chroma_client = chromadb.PersistentClient(path="./smart_chroma_db")
        self.collection = self.chroma_client.get_or_create_collection("smart_company_info")
        print("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì™„ë£Œ")
    
    def load_word_file(self, file_path):
        """Word íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ë‹¨ë³„ë¡œ ë¶„ë¦¬"""
        print(f"ğŸ“„ Word íŒŒì¼ ì½ê¸°: {file_path}")
        
        if not os.path.exists(file_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return []
        
        doc = Document(file_path)
        texts = []
        
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if text and len(text) > 5:
                texts.append({
                    'id': f'para_{i}',
                    'text': text
                })
        
        print(f"âœ… {len(texts)}ê°œì˜ ë¬¸ë‹¨ì„ ì½ì—ˆìŠµë‹ˆë‹¤")
        return texts
    
    def load_text_file(self, file_path):
        """í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ë‹¨ë³„ë¡œ ë¶„ë¦¬"""
        print(f"ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°: {file_path}")
        
        if not os.path.exists(file_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return []
        
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
        
        lines = content.split('\n')
        texts = []
        
        for i, line in enumerate(lines):
            line = line.strip()
            if line and len(line) > 5:
                texts.append({
                    'id': f'line_{i}',
                    'text': line
                })
        
        print(f"âœ… {len(texts)}ê°œì˜ ì •ë³´ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤")
        return texts
    
    def add_documents(self, texts):
        """ë¬¸ì„œë“¤ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€"""
        print("ğŸ”„ ì •ë³´ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€ ì¤‘...")
        
        try:
            self.chroma_client.delete_collection("smart_company_info")
            self.collection = self.chroma_client.create_collection("smart_company_info")
        except:
            pass
        
        documents = [item['text'] for item in texts]
        ids = [item['id'] for item in texts]
        
        self.collection.add(
            documents=documents,
            ids=ids
        )
        
        print(f"âœ… {len(documents)}ê°œ ì •ë³´ ì¶”ê°€ ì™„ë£Œ")
    
    def search_documents(self, query, top_k=3):
        """ë¬¸ì„œ ê²€ìƒ‰ (GPT ì „ ë‹¨ê³„)"""
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k
        )
        
        if results['documents'][0]:
            return results['documents'][0]
        return []
    
    def generate_answer_with_gpt(self, question, context_docs):
        """GPTë¥¼ ì‚¬ìš©í•´ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±"""
        
        if not self.client:
            return "OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        if not context_docs:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
        context = "\n".join([f"- {doc}" for doc in context_docs])
        
        # GPTì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¹ì‹ ì€ íšŒì‚¬ì˜ IT ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì•„ë˜ íšŒì‚¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

íšŒì‚¬ ì •ë³´:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€ ê·œì¹™:
1. ìœ„ì˜ íšŒì‚¬ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ì •ë³´ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë§í•˜ì„¸ìš”
3. ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
4. êµ¬ì²´ì ì¸ ì •ë³´(ë¹„ë°€ë²ˆí˜¸, IPì£¼ì†Œ ë“±)ê°€ ìˆìœ¼ë©´ ì •í™•íˆ í¬í•¨í•˜ì„¸ìš”

ë‹µë³€:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"âŒ GPT API ì˜¤ë¥˜: {e}")
            return f"API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ì •ë³´: {context_docs[0] if context_docs else 'ì—†ìŒ'}"
    
    def smart_search(self, query):
        """ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰: RAG + GPT"""
        print(f"ğŸ” ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰: '{query}'")
        
        # 1ë‹¨ê³„: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        context_docs = self.search_documents(query, top_k=3)
        print(f"ğŸ“‹ {len(context_docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬")
        
        # 2ë‹¨ê³„: GPTë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±
        answer = self.generate_answer_with_gpt(query, context_docs)
        
        return answer, context_docs
    
    def chat(self):
        """ëŒ€í™”í˜• ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ"""
        print("\nğŸ¤– GPT í†µí•© íšŒì‚¬ ì •ë³´ ì±—ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ ì´ì œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
        print("ğŸ’¡ 'ì¢…ë£Œ' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
        print("-" * 60)
        
        while True:
            query = input("\nâ“ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ").strip()
            
            if query.lower() in ['ì¢…ë£Œ', 'quit', 'exit', 'ë‚˜ê°€ê¸°']:
                print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤!")
                break
            
            if not query:
                continue
            
            answer, context_docs = self.smart_search(query)
            
            print(f"\nğŸ¤– ë‹µë³€:")
            print(answer)
            
            # ì°¸ê³  ë¬¸ì„œë„ í‘œì‹œ (ì˜µì…˜)
            if context_docs and len(context_docs) > 1:
                print(f"\nğŸ“š ì°¸ê³  ì •ë³´:")
                for i, doc in enumerate(context_docs[:2], 1):
                    print(f"  {i}. {doc}")

def main():
    print("ğŸš€ GPT í†µí•© ìŠ¤ë§ˆíŠ¸ RAG ì‹œìŠ¤í…œ ì‹œì‘!\n")
    
    rag = SmartRAGWithGPT()
    
    if not rag.client:
        return
    
    # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    file_path = "pstorm_pw.docx"  # ğŸ‘ˆ ì‹¤ì œ Word íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½
    
    # íŒŒì¼ ì½ê¸°
    if file_path.endswith('.docx'):
        texts = rag.load_word_file(file_path)
    else:
        texts = rag.load_text_file(file_path)
    
    if not texts:
        print("âŒ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    rag.add_documents(texts)
    
    print("\nğŸ¯ ìŠ¤ë§ˆíŠ¸ í…ŒìŠ¤íŠ¸:")
    test_queries = [
        "ì™€ì´íŒŒì´ ë¹„ë°€ë²ˆí˜¸ê°€ ë­ì•¼?",
        "êµ¬ê¸€ ê³„ì • ì •ë³´ ì•Œë ¤ì¤˜",
        "í”„ë¦°í„°ê°€ ì•ˆ ë˜ëŠ”ë° ì–´ë–»ê²Œ í•´?"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” ì§ˆë¬¸: '{query}'")
        answer, _ = rag.smart_search(query)
        print(f"ğŸ¤– ë‹µë³€: {answer}")
    
    rag.chat()

if __name__ == "__main__":
    main()